{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from NetworkAPI import NetworkAPI\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.RandomCrop(28, padding=4),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: torchvision.datasets.CIFAR10(root='./data', \n",
    "                                                  transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=256, \n",
    "                                              shuffle=True, \n",
    "                                              num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMaxMax, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epochs\n",
    "\n",
    "2 sekwencje: Conv, ReLU, Batch, Conv, ReLU, Batch, Pool\n",
    "\n",
    "Wszystkie kombinacje Pooli:\n",
    "\n",
    "* Max -- Max\n",
    "* Max -- Avg\n",
    "* Avg -- Max\n",
    "* Avg -- Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max -- Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkMaxMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMaxMax, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x64x64\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkMaxMax().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_MaxMax', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max -- Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkMaxAvg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMaxAvg, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkMaxAvg().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_MaxAvg', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max -- No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkMaxNo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMaxNo, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkMaxNo().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_MaxNo', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max -- Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkMaxConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkMaxConv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkMaxConv().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_MaxConv', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg -- Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAvgMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkAvgMax, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkAvgMax().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_AvgMax', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg -- Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAvgAvg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkAvgAvg, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkAvgAvg().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_AvgAvg', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg -- No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAvgNo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkAvgNo, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkAvgNo().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_AvgNo', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg -- Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAvgConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkAvgConv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkAvgConv().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_AvgConv', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No -- Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNoMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkNoMax, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkNoMax().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_NoMax', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No -- Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNoAvg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkNoAvg, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkNoAvg().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_NoAvg', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No -- No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNoNo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkNoNo, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkNoNo().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_NoNo', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No -- Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNoConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkNoConv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkNoConv().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_NoConv', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv -- Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConvMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConvMax, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkConvMax().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_ConvMax', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv -- Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConvAvg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConvAvg, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkConvAvg().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_ConvAvg', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv -- No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConvNo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConvNo, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkConvNo().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_ConvNo', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv -- Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConvConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkConvConv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1), # Output is 32x16x16\n",
    "            nn.Dropout2d(0.2) # Output is 32x16x16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x16x16\n",
    "            nn.ReLU(inplace=True), # Output is 64x16x16\n",
    "            nn.BatchNorm2d(64), # Output is 64x16x16\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1), # Output is 64x8x8\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*8*8)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkConvConv().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_ConvConv', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "#brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EverySequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkEverySequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkEverySequence, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkEverySequence().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_batch_EverySequence', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FirstSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkFirstSequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkFirstSequence, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkFirstSequence().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_batch_FirstSequence', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EveryOfFirstSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkEveryOfFirstSequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkEveryOfFirstSequence, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkEveryOfFirstSequence().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_batch_EveryOfFirstSequence', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SecondSequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkSecondSequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkSecondSequence, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkSecondSequence().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_batch_SecondSequence', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNoDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkNoDropout, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkNoDropout().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_dropout_NoDropout', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FirstSequenceDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkFirstSequenceDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkFirstSequenceDropout, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.5) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkFirstSequenceDropout().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_dropout_FirstSequenceDropout', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FirstSmallSequenceDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkFirstSmallSequenceDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkFirstSmallSequenceDropout, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkFirstSmallSequenceDropout().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_dropout_FirstSmallSequenceDropout', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwapedDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkSwapedDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkSwapedDropout, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Dropout2d(0.3) # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.2) # Output is 64x32x32\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkSwapedDropout().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_dropout_SwapedDropout', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinalSequenceDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkFinalSequenceDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkFinalSequenceDropout, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1), # Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),# Output is 32x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 32x32x32\n",
    "            nn.BatchNorm2d(32), # Output is 32x32x32\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),# Output is 64x32x32\n",
    "            nn.ReLU(inplace=True), # Output is 64x32x32\n",
    "            nn.BatchNorm2d(64), # Output is 64x32x32\n",
    "            nn.Dropout2d(0.3) # Output is 64x32x32\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.Linear(256,64)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,10),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) # Change size from 3x32x32 to 32x16x16\n",
    "        x = self.conv2(x) # Change size from 32x16x16 to 64x16x16\n",
    "        x = x.view(-1, 64*32*32)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 0\n",
    "\n",
    "model = NetworkFinalSequenceDropout().to(device)\n",
    "brain = NetworkAPI(model, dataloaders, 'arch_dropout_FinalSequenceDropout', optim.SGD(model.parameters(), lr=0.1), lr=0.1)\n",
    "# brain.load_checkpoint()\n",
    "errors = brain.train_loop(epochs=eps)\n",
    "brain.plot_errors()\n",
    "brain.plot_accuracy()\n",
    "brain.class_accuracy(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
